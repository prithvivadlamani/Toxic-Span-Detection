Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 encoder_input_ids (InputLayer)  [(None, 400)]       0           []                               
                                                                                                  
 encoder_attention_mask (InputL  [(None, 400)]       0           []                               
 ayer)                                                                                            
                                                                                                  
 encoder_token_type_ids (InputL  [(None, 400)]       0           []                               
 ayer)                                                                                            
                                                                                                  
 tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['encoder_input_ids[0][0]',      
                                thPoolingAndCrossAt               'encoder_attention_mask[0][0]', 
                                tentions(last_hidde               'encoder_token_type_ids[0][0]'] 
                                n_state=(None, 400,                                               
                                 768),                                                            
                                 pooler_output=(Non                                               
                                e, 768),                                                          
                                 past_key_values=No                                               
                                ne, hidden_states=N                                               
                                one, attentions=Non                                               
                                e, cross_attentions                                               
                                =None)                                                            
                                                                                                  
 lstm (LSTM)                    (None, 400, 512)     2623488     ['tf_bert_model[0][0]']          
                                                                                                  
 dense (Dense)                  (None, 400, 3)       1539        ['lstm[0][0]']                   
                                                                                                  
 length (InputLayer)            [(None, 1)]          0           []                               
                                                                                                  
 crf_layer (CRFLayer)           (None, 400, 3)       9           ['dense[0][0]',                  
                                                                  'length[0][0]']                 
                                                                                                  
==================================================================================================
Total params: 112,107,276
Trainable params: 112,107,276
Non-trainable params: 0
__________________________________________________________________________________________________